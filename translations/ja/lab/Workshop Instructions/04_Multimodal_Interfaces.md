# パート3 - マルチモーダル

これまで、LLMとのやり取りは1つのモダリティのみを使用していました。つまり、テキストを入力し、テキストまたは画像を出力として受け取る形です。しかし、マルチモーダルインターフェースは、テキスト、画像、音声など複数のモダリティを活用してモデルとやり取りできるため、ユーザー体験を向上させる手段としてますます注目されています。このセクションでは、**GPT-4o mini** および **GPT-4o audio** を使用してマルチモーダルインターフェースとやり取りする方法を探ります。

> [!TIP]  
> **GPT-4o mini** は、自然言語処理と視覚理解を組み合わせたマルチモーダルモデルです。テキストと画像を組み合わせた入力を処理し、両方のモダリティに関連する出力を生成できます。

**GPT-4o realtime** は、低遅延の「音声入力、音声出力」による会話型インタラクションをサポートします。これは、カスタマーサポートエージェント、音声アシスタント、リアルタイム翻訳など、ユーザーとモデルのライブインタラクションを必要とするユースケースに最適です。

## ベストプラクティス

- **文脈の具体性**: 現在のシナリオに文脈を追加することで、モデルが適切な出力を理解しやすくなります。この具体性は、関連する側面に焦点を当て、不要な詳細を避けるのに役立ちます。​

- **タスク指向のプロンプト**: 特定のタスクに焦点を当てることで、モデルがその視点を考慮しながら出力を生成するのを助けます。​

- **出力形式の定義**: 出力の形式を明確に指定します（例: Markdown、JSON、HTMLなど）。また、特定の構造や長さ、応答に関する具体的な属性を提案することもできます。​

- **拒否への対応**: モデルがタスクを実行できないと示した場合、プロンプトを調整することで解決できることがあります。より具体的なプロンプトは、モデルに明確な理解とより良い実行を促します。以下の点を考慮してください:  
    - モデルの出力の透明性を高めるために、生成された応答について説明を求める  
    - 単一画像プロンプトを使用する場合、画像をテキストの前に配置する  
    - モデルに最初に画像を詳細に説明させ、その説明から特定のタスクを完了させる  

- **プロンプトチューニング**: テキスト生成シナリオで探ったプロンプトチューニング技術を試してみてください:  
    - リクエストを分解する（例: チェーンオブソート）  
    - 例を追加する（例: 少数ショット学習）  

## 画像を使用したモデルとのやり取り

1. **playgrounds** セクションに移動し、**Try the Chat Playground** を選択します。

>[!alert] 開始する前に、**Clear Chat** をクリックして、以前のやり取りからのコンテキストを削除してください。

2. チャットテキストボックスで、添付アイコンをクリックしてローカル画像をアップロードします。

![画像を入力としてアップロード](../../../../lab/Workshop Instructions/Images/upload_image_icon.png)

3. デスクトップの ```house-multimodal``` フォルダーからすべての画像を選択します。  
4. ファイルをアップロードしたら、以下のプロンプトを試して画像とのやり取りを開始します:

```
Create a tagline and short description for this rental home advertisement.
- The first picture is from the home
- The other pictures are from sights nearby
- In the description use the features of the house and make the ad more compelling with the sights. 
- Do not talk about features not visible in the images.
- If you have information about the location of the images, use that information in the description
```

## 文脈の提供

次のデモでは、遮られた画像を使用します。この画像には意図的にバウンディングボックスが追加され、全体の文脈が隠されています。

1. _Clear the chat_ を実行し、チャットテキストボックスに次のプロンプトを追加します: ``what is that?``  
2. 添付アイコンをクリックし、デスクトップフォルダーに移動して [context-001](./Images/context-001.png) 画像をアップロードし、プロンプトを送信します。

> もし私が「これ何ですか？」と尋ねた場合、このテキストを識別するのは難しいかもしれません。これは、光学文字認識における典型的なコンピュータビジョンの課題を示しています: 不明瞭で孤立した単語を解読することです。ここで gpt-4o-mini を使用して「これ何ですか？」と尋ねると、「手書きスタイルのため、テキストははっきり読めません。“Mark” のようなものかもしれません。」と応答します。また、「テキストの一部は遮られており、読むことができません。」とも指摘します。

3. 新しい画像を追加します。デスクトップフォルダーに移動し、[context-002](./Images/context-002.png) 画像をチャットにアップロードし、プロンプト ```Extract all the texts from the image. Explain what you think this is.``` を送信します。

> 少し情報が増えても、まだ何であるかを特定するのは非常に困難です。この場合、プロンプトを少し調整して「画像からすべてのテキストを抽出してください。これが何であると思うか説明してください。」とします。gpt-4o-mini は「これは 'milk, steak' と書かれており、買い物リストのように見えます。」と応答します。また、画像がまだ部分的に隠れていることも指摘しており、非常に興味深いです。

4. 最後の画像を追加します。デスクトップフォルダーに移動し、[context-003](./Images/demo-4-context-003.png) 画像をチャットにアップロードし、プロンプト ```Extract all the texts from the image. Explain what you think this is.``` を送信します。

> 全体の画像が明らかになると、gpt-4o-mini の推測が正しかったことがわかります—これは買い物リストです。'mayo' や 'organic bread' といった項目を正確に識別します。さらに興味深いのは、下部のメモの解釈です。「ビール項目に関するメモは、節度や数量制限を強調するリマインダーを示しているようです。」と述べています。

## リアルタイム音声インタラクション

**gpt-4o-realtime-preview** モデルを統合することで、ユーザーは音声コマンドを使用してプラットフォームとやり取りでき、ショッピング体験がより魅力的でアクセスしやすくなります。

1. **Playgrounds** に戻り、**try Real-time audio playground** を選択し、デプロイメントを **gpt-4o-realtime-preview** に設定します。

2. **model instructions box** に次の内容を更新します:

    ```You are a pirate, and every response must be full of pirate lingo. ```

3. Playground で **enable microphone** をクリックします。ポップアップが表示されたら、音声でのインタラクションを有効にするために「許可」をクリックします。

![AI Foundry で音声を有効化](../../../../lab/Workshop Instructions/Images/aifoundry-enable-audio.jpeg)

4. **start listening** ボタンをクリックしてモデルとやり取りします。「`hello`」と言い、モデルにいくつかの事実を尋ねてみてください。

5. 次に、システムメッセージを以下のように変更してトーンを変え、再びモデルとやり取りします:

```You are a valiant medieval knight. Every response should echo the chivalry, honor, and grandeur of the court. Speak with formality and grace, as if addressing kings, queens, and noble warriors.```

## 次のステップ

おめでとうございます！これでラボの第3部を完了し、マルチモーダルモデルとのやり取り方法を学びました。

[パート4: Azure AI Agents](./05_AI_Agents.md) に進みましょう。

**免責事項**:  
本書類は、機械翻訳AIサービスを使用して翻訳されています。正確性を期すよう努めておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された原文を信頼できる情報源としてお考えください。重要な情報については、専門の人間による翻訳をお勧めします。本翻訳の使用に起因する誤解や誤解釈について、当社は一切の責任を負いかねます。